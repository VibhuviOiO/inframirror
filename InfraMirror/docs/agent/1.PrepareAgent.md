# Step 1: Prepare Agent Entity for Self-Registration

## Goal
Enhance Agent entity with all properties needed for Datadog-style self-registration.

## Requirements

### Properties from AgentRegistrationRequestDTO
All fields that agent sends during registration must be stored in Agent entity:
- `name` - Agent identifier
- `hostname` - Server hostname
- `ipAddress` - Agent IP address
- `osType` - Operating system (Linux, Windows, macOS)
- `osVersion` - OS version details
- `agentVersion` - Agent software version
- `tags` - Metadata (region, datacenter, environment, etc.)

### Additional Properties for Tracking
- `lastSeenAt` - Last heartbeat timestamp
- `status` - Agent health status (ACTIVE, INACTIVE, OFFLINE)
- `datacenter` - Direct link to datacenter (from tags)
- `region` - Link to region (existing field)

## Agent Entity Changes

### Add to Agent.java

```java
@Size(max = 255)
@Column(name = "hostname", length = 255)
private String hostname;

@Size(max = 45)
@Column(name = "ip_address", length = 45)
private String ipAddress;

@Size(max = 50)
@Column(name = "os_type", length = 50)
private String osType;

@Size(max = 100)
@Column(name = "os_version", length = 100)
private String osVersion;

@Size(max = 20)
@Column(name = "agent_version", length = 20)
private String agentVersion;

@Column(name = "last_seen_at")
private Instant lastSeenAt;

@Size(max = 20)
@Column(name = "status", length = 20)
private String status; // ACTIVE, INACTIVE, OFFLINE

@Column(name = "tags", columnDefinition = "jsonb")
@Type(JsonNodeType.class)
private JsonNode tags;

@ManyToOne(fetch = FetchType.LAZY)
@JsonIgnoreProperties(value = { "region" }, allowSetters = true)
private Datacenter datacenter;
```

## Database Migration (Single Changelog)

**File**: `src/main/resources/config/liquibase/changelog/20250122000001_update_agent.xml`

```xml
<?xml version="1.0" encoding="utf-8"?>
<databaseChangeLog
    xmlns="http://www.liquibase.org/xml/ns/dbchangelog"
    xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:schemaLocation="http://www.liquibase.org/xml/ns/dbchangelog http://www.liquibase.org/xml/ns/dbchangelog/dbchangelog-latest.xsd">

    <changeSet id="20250122000001-1" author="system">
        <addColumn tableName="agent">
            <column name="hostname" type="varchar(255)">
                <constraints nullable="true"/>
            </column>
            <column name="ip_address" type="varchar(45)">
                <constraints nullable="true"/>
            </column>
            <column name="os_type" type="varchar(50)">
                <constraints nullable="true"/>
            </column>
            <column name="os_version" type="varchar(100)">
                <constraints nullable="true"/>
            </column>
            <column name="agent_version" type="varchar(20)">
                <constraints nullable="true"/>
            </column>
            <column name="last_seen_at" type="timestamp">
                <constraints nullable="true"/>
            </column>
            <column name="status" type="varchar(20)" defaultValue="ACTIVE">
                <constraints nullable="true"/>
            </column>
            <column name="tags" type="jsonb">
                <constraints nullable="true"/>
            </column>
            <column name="datacenter_id" type="bigint">
                <constraints nullable="true"/>
            </column>
        </addColumn>
    </changeSet>

    <changeSet id="20250122000001-2" author="system">
        <addForeignKeyConstraint
            baseTableName="agent"
            baseColumnNames="datacenter_id"
            constraintName="fk_agent_datacenter_id"
            referencedTableName="datacenter"
            referencedColumnNames="id"/>
    </changeSet>

</databaseChangeLog>
```

## Update AgentDTO

**File**: `src/main/java/vibhuvi/oio/inframirror/service/dto/AgentDTO.java`

```java
// Add these fields
private String hostname;
private String ipAddress;
private String osType;
private String osVersion;
private String agentVersion;
private Instant lastSeenAt;
private String status;
private JsonNode tags;
private Long datacenterId;
private DatacenterDTO datacenter;
```

## Update AgentMapper

**File**: `src/main/java/vibhuvi/oio/inframirror/service/mapper/AgentMapper.java`

```java
@Mapping(source = "datacenter.id", target = "datacenterId")
AgentDTO toDto(Agent agent);

@Mapping(source = "datacenterId", target = "datacenter")
Agent toEntity(AgentDTO agentDTO);
```

## High Availability (HA) Support

### Multiple Agents in One Datacenter

**Scenario 1: Active-Passive HA**
```
Agent 1: agent-dc1-primary (ACTIVE)
Agent 2: agent-dc1-backup (INACTIVE)
Both in: Datacenter "DC1"
```

**How it works**:
- Both agents have same configuration
- Use AgentLock table for leader election
- Only ACTIVE agent submits heartbeats
- If primary fails, backup becomes ACTIVE

**Configuration**:
```yaml
# agent-config.yml (same for both)
agent:
  name: "agent-dc1-primary"  # or "agent-dc1-backup"
  tags:
    region: "US East"
    datacenter: "DC1"
    ha_mode: "active-passive"
    ha_group: "dc1-ha-group"
```

**Scenario 2: Multiple Agents with Different Configs**
```
Agent 1: agent-dc1-network (monitors network)
Agent 2: agent-dc1-database (monitors databases)
Both in: Datacenter "DC1"
```

**How it works**:
- Each agent has different name
- Each monitors different instances/services
- No conflict - different responsibilities

**Configuration**:
```yaml
# Agent 1
agent:
  name: "agent-dc1-network"
  tags:
    datacenter: "DC1"
    role: "network-monitoring"

# Agent 2
agent:
  name: "agent-dc1-database"
  tags:
    datacenter: "DC1"
    role: "database-monitoring"
```

### Database Support for Multiple Agents

**Agent Table**:
- `name` is unique identifier (not datacenter)
- Multiple agents can have same `datacenter_id`
- Each agent has unique `id`

**AgentLock Table** (already exists):
- Used for HA leader election
- Lock by datacenter or custom group
- Prevents duplicate monitoring

**Query Examples**:
```sql
-- Get all agents in a datacenter
SELECT * FROM agent WHERE datacenter_id = 1;

-- Get active agent in datacenter (HA)
SELECT * FROM agent 
WHERE datacenter_id = 1 
AND status = 'ACTIVE' 
LIMIT 1;

-- Get agent by name (unique)
SELECT * FROM agent WHERE name = 'agent-dc1-primary';
```

## Agent Properties Summary

| Field | Type | Required | Purpose | Example |
|-------|------|----------|---------|---------|
| `id` | Long | Yes | Primary key | 1 |
| `name` | String(50) | Yes | Unique agent identifier | "agent-aws-us-east-1" |
| `hostname` | String(255) | No | Server hostname | "ip-10-0-1-5.ec2.internal" |
| `ipAddress` | String(45) | No | Agent IP | "10.0.1.5" |
| `osType` | String(50) | No | Operating system | "Linux" |
| `osVersion` | String(100) | No | OS version | "Ubuntu 22.04" |
| `agentVersion` | String(20) | No | Agent software version | "1.0.0" |
| `lastSeenAt` | Instant | No | Last heartbeat time | 2025-01-22T10:00:00Z |
| `status` | String(20) | No | Health status | "ACTIVE" |
| `tags` | JSONB | No | Metadata | {"environment": "prod"} |
| `datacenterId` | Long | No | Datacenter FK | 5 |
| `regionId` | Long | No | Region FK (existing) | 1 |

## Tags JSONB Structure

```json
{
  "region": "AWS US East",
  "datacenter": "Virginia DC1",
  "environment": "production",
  "cloud_provider": "aws",
  "ha_mode": "active-passive",
  "ha_group": "dc1-ha-group",
  "team": "platform",
  "custom_key": "custom_value"
}
```

## Implementation Steps

### Step 1: Update Agent Entity
```bash
# File: src/main/java/vibhuvi/oio/inframirror/domain/Agent.java
# Add all new fields with getters/setters
```

### Step 2: Create Database Migration
```bash
# File: src/main/resources/config/liquibase/changelog/20250122000001_update_agent.xml
# Single changelog with all changes
```

### Step 3: Update master changelog
```xml
<!-- File: src/main/resources/config/liquibase/master.xml -->
<include file="config/liquibase/changelog/20250122000001_update_agent.xml" relativeToChangelogFile="false"/>
```

### Step 4: Update AgentDTO
```bash
# File: src/main/java/vibhuvi/oio/inframirror/service/dto/AgentDTO.java
# Add all new fields
```

### Step 5: Update AgentMapper
```bash
# File: src/main/java/vibhuvi/oio/inframirror/service/mapper/AgentMapper.java
# Add datacenter mapping
```

### Step 6: Update AgentRepository (optional)
```java
// Add to AgentRepository.java
Optional<Agent> findByName(String name);
Optional<Agent> findByHostname(String hostname);
List<Agent> findByDatacenterId(Long datacenterId);
List<Agent> findByDatacenterIdAndStatus(Long datacenterId, String status);
```

## Validation

### Test Database Migration
```bash
# 1. Clean database (development mode)
docker-compose -f docker/services.yml down -v
docker-compose -f docker/services.yml up -d

# 2. Run application
./mvnw

# 3. Check database
docker exec -it inframirror-postgres psql -U inframirror -d inframirror

# 4. Verify columns
\d agent

# Expected new columns:
# - hostname
# - ip_address
# - os_type
# - os_version
# - agent_version
# - last_seen_at
# - status
# - tags
# - datacenter_id
```

### Test via UI
```bash
# 1. Navigate to: http://localhost:8080/agent
# 2. Create new agent with all fields
# 3. Verify data persists correctly
# 4. Check tags are stored as JSONB
```

## Acceptance Criteria

- [ ] Agent entity has all AgentRegistrationRequestDTO fields
- [ ] Database migration runs successfully
- [ ] AgentDTO includes all new fields
- [ ] AgentMapper handles datacenter relationship
- [ ] Multiple agents can exist in same datacenter
- [ ] Tags stored as JSONB
- [ ] Existing agents still work (backward compatible)
- [ ] UI can display new fields

## HA Scenarios Supported

### Scenario 1: Active-Passive HA
✅ Two agents, same config, same datacenter
✅ Use AgentLock for leader election
✅ Only one agent ACTIVE at a time

### Scenario 2: Load Balancing
✅ Multiple agents, same datacenter
✅ Each monitors different instances
✅ All agents ACTIVE simultaneously

### Scenario 3: Specialized Agents
✅ Multiple agents, same datacenter
✅ Each has different role (network, database, etc.)
✅ Different configurations via tags

## Next Steps

Once Agent entity is ready:
→ **Step 2**: Create Agent Registration API
→ **Step 3**: Create Infrastructure Reporting API
→ **Step 4**: Create Batch Heartbeat Ingestion API

## Notes

- **No API Key Type**: Single API key works for all operations
- **Single Liquibase File**: All Agent changes in one changelog
- **HA Support**: Multiple agents per datacenter supported
- **Backward Compatible**: Existing agents work without new fields
- **Validation from UI**: No complex backend validation needed
- **Clean Development**: Can re-run with fresh database anytime
